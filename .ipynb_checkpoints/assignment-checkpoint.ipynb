{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37514a60-b7df-4e26-8be6-800b7a9e9f81",
   "metadata": {},
   "source": [
    "# Hands-On Assignment 5\n",
    "\n",
    "In this assignment, you will practice everything that you have learned so far in an end-to-end setting.\n",
    "You will be provided with a dataset that is **unique to you**, and your task is to perform\n",
    "all the steps from previous assignments to clean, explore, visualize, and analyze your dataset.\n",
    "\n",
    "**Written Portion**: Additionally, you will create a report that describes your process and provides insights about your dataset.\n",
    "Each section that should appear in your report is noted with an orange star (like normal HO tasks).  The report should be  4-6 pages (12 pt font, 1.5 line spacing), and turned in on Canvas as a PDF.\n",
    "\n",
    "The coding aspect for this assignment will be turned in the same was as all other HO's,\n",
    "by submitting this file to the autograder.\n",
    "\n",
    "\n",
    "For this assignment, feel free to make additional functions instead of implementing everything in the provided function.\n",
    "\n",
    "The objective of this assignment is for you to apply and solidify the skills you have learned in previous assignments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25860737-2a22-4dd3-8f9c-1f8039f1a67f",
   "metadata": {},
   "source": [
    "# Prompt\n",
    "\n",
    "You have graduated from this class, and are a huge success!\n",
    "You landed a job doing data science at some fancy company.\n",
    "\n",
    "You just got a new client with some really interesting problems you get to solve.\n",
    "Unfortunately, because of a big mess-up on their side the data's metadata got corrupted\n",
    "(and the person that used to maintain the data just took a vow of silence and moved to a bog).\n",
    "\n",
    "The only column you are sure about is the `label` column,\n",
    "which contains a numeric label for each row.\n",
    "Aside from that, the client does not know anything about the names, content, or even data types for each column.\n",
    "\n",
    "Your task is to explore, clean, and analyze this data.\n",
    "You should have already received an email with the details on obtaining your unique data.\n",
    "Place it in the same directory as this notebook (and your `local_grader.py` script) and name it `data.txt`.\n",
    "\n",
    "*I know this prompt may sound unrealistic, but I have literally been in a situation exactly like this.\n",
    "I was working at a database startup, and one of our clients gave us data with over 70 columns and more than a million records and told us:\n",
    "\"The person who used to manage the data is no longer working with us, but this was the data they used to make all their decisions.\n",
    "We also lost all the metadata information, like column names.\"\n",
    "...\n",
    "Working in industry is not always glamorous.\n",
    "-Eriq*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb229b6-7448-4d18-8d66-ae09853ed1cd",
   "metadata": {},
   "source": [
    "# Part 0: Explore Your Data\n",
    "\n",
    "Before you start doing things to/with your data, it's always a good idea to load up your data and take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb1e1f63-a84d-4452-b52b-1aacaee00148",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>col_00</th>\n",
       "      <th>col_01</th>\n",
       "      <th>col_02</th>\n",
       "      <th>col_03</th>\n",
       "      <th>col_04</th>\n",
       "      <th>col_05</th>\n",
       "      <th>col_06</th>\n",
       "      <th>col_07</th>\n",
       "      <th>col_08</th>\n",
       "      <th>col_09</th>\n",
       "      <th>col_10</th>\n",
       "      <th>col_11</th>\n",
       "      <th>col_12</th>\n",
       "      <th>col_13</th>\n",
       "      <th>col_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>852 m^3</td>\n",
       "      <td>0.1976</td>\n",
       "      <td>ferret</td>\n",
       "      <td>cOMPUTER gAME dESIGN</td>\n",
       "      <td>1.1539</td>\n",
       "      <td>852.0</td>\n",
       "      <td>MOTOR SPORTS</td>\n",
       "      <td>1057 kg/s</td>\n",
       "      <td>695</td>\n",
       "      <td>194</td>\n",
       "      <td>TENNIS</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.5269</td>\n",
       "      <td>522.0</td>\n",
       "      <td>0.9031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1292 m^3</td>\n",
       "      <td>0.9112</td>\n",
       "      <td>dog</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>545.0</td>\n",
       "      <td>boxing</td>\n",
       "      <td>871 kg/s</td>\n",
       "      <td>1218</td>\n",
       "      <td>127</td>\n",
       "      <td>soccer</td>\n",
       "      <td>0.6179</td>\n",
       "      <td>0.8914</td>\n",
       "      <td>765.0</td>\n",
       "      <td>0.5337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>401 m^3</td>\n",
       "      <td>0.5994</td>\n",
       "      <td>chicken</td>\n",
       "      <td>Human Computer Interaction</td>\n",
       "      <td>0.7812</td>\n",
       "      <td>907.0</td>\n",
       "      <td>motor sports</td>\n",
       "      <td>1304 kg/s</td>\n",
       "      <td>1029</td>\n",
       "      <td>66</td>\n",
       "      <td>tennis</td>\n",
       "      <td>0.9529</td>\n",
       "      <td>1.243</td>\n",
       "      <td>604.0</td>\n",
       "      <td>0.8488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-459 m^3</td>\n",
       "      <td>1.1289</td>\n",
       "      <td>reptile</td>\n",
       "      <td>Computer Engineering, Bioengineering, Computer...</td>\n",
       "      <td>0.857</td>\n",
       "      <td>171.0</td>\n",
       "      <td>ice hockey</td>\n",
       "      <td>-1 kg/s</td>\n",
       "      <td>267</td>\n",
       "      <td>1205</td>\n",
       "      <td>tennis</td>\n",
       "      <td>1.2144</td>\n",
       "      <td>0.4116</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.9313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>383 m^3</td>\n",
       "      <td>0.1356</td>\n",
       "      <td>chicken</td>\n",
       "      <td>Natural Language Processing</td>\n",
       "      <td>0.4691</td>\n",
       "      <td>838.0</td>\n",
       "      <td>boxing</td>\n",
       "      <td>767 kg/s</td>\n",
       "      <td>992</td>\n",
       "      <td>1087</td>\n",
       "      <td>boxing</td>\n",
       "      <td>1.0093</td>\n",
       "      <td>0.9663</td>\n",
       "      <td>794.0</td>\n",
       "      <td>0.8494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5347</td>\n",
       "      <td>cat</td>\n",
       "      <td>Computational Media, Statistics</td>\n",
       "      <td>0.74</td>\n",
       "      <td>701.0</td>\n",
       "      <td>volleyball</td>\n",
       "      <td>1014 kg/s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-108</td>\n",
       "      <td>basketball</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>0.2866</td>\n",
       "      <td>481.0</td>\n",
       "      <td>0.8878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>5</td>\n",
       "      <td>804 m^3</td>\n",
       "      <td>1.0807</td>\n",
       "      <td>rat</td>\n",
       "      <td>Technology and Information Management, Games a...</td>\n",
       "      <td>1.0517</td>\n",
       "      <td>1568.0</td>\n",
       "      <td>tennis</td>\n",
       "      <td>-309 kg/s</td>\n",
       "      <td>643</td>\n",
       "      <td>621</td>\n",
       "      <td>golf, ice hockey</td>\n",
       "      <td>0.4413</td>\n",
       "      <td>0.9347</td>\n",
       "      <td>1259.0</td>\n",
       "      <td>0.9875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>4</td>\n",
       "      <td>34 m^3</td>\n",
       "      <td>0.8205</td>\n",
       "      <td>reptile</td>\n",
       "      <td>Bioengineering</td>\n",
       "      <td>1.2055</td>\n",
       "      <td>431.0</td>\n",
       "      <td>ice hockey</td>\n",
       "      <td>843 kg/s</td>\n",
       "      <td>1170</td>\n",
       "      <td>1442</td>\n",
       "      <td>tennis</td>\n",
       "      <td>0.9688</td>\n",
       "      <td>0.3956</td>\n",
       "      <td>347.0</td>\n",
       "      <td>0.8059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>0</td>\n",
       "      <td>815 m^3</td>\n",
       "      <td>0.6873</td>\n",
       "      <td>fish</td>\n",
       "      <td>Statistics, Computational Media</td>\n",
       "      <td>0.7707</td>\n",
       "      <td>851.0</td>\n",
       "      <td>golf</td>\n",
       "      <td>1129 kg/s</td>\n",
       "      <td>1033</td>\n",
       "      <td>554</td>\n",
       "      <td>basketball</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.362</td>\n",
       "      <td>846.0</td>\n",
       "      <td>1.0954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>1</td>\n",
       "      <td>1173 m^3</td>\n",
       "      <td>0.5848</td>\n",
       "      <td>dog</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>-0.1426</td>\n",
       "      <td>709.0</td>\n",
       "      <td>track &amp; field</td>\n",
       "      <td>1066 kg/s</td>\n",
       "      <td>495</td>\n",
       "      <td>1252</td>\n",
       "      <td>soccer</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.9962</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.2085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>834 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label    col_00  col_01   col_02  \\\n",
       "0        2   852 m^3  0.1976   ferret   \n",
       "1        1  1292 m^3  0.9112      dog   \n",
       "2        3   401 m^3  0.5994  chicken   \n",
       "3        4  -459 m^3  1.1289  reptile   \n",
       "4        3   383 m^3  0.1356  chicken   \n",
       "..     ...       ...     ...      ...   \n",
       "829      0       NaN  0.5347      cat   \n",
       "830      5   804 m^3  1.0807      rat   \n",
       "831      4    34 m^3  0.8205  reptile   \n",
       "832      0   815 m^3  0.6873     fish   \n",
       "833      1  1173 m^3  0.5848      dog   \n",
       "\n",
       "                                                col_03   col_04  col_05  \\\n",
       "0                                 cOMPUTER gAME dESIGN   1.1539   852.0   \n",
       "1                                         Data Science   0.0172   545.0   \n",
       "2                           Human Computer Interaction   0.7812   907.0   \n",
       "3    Computer Engineering, Bioengineering, Computer...    0.857   171.0   \n",
       "4                          Natural Language Processing   0.4691   838.0   \n",
       "..                                                 ...      ...     ...   \n",
       "829                    Computational Media, Statistics     0.74   701.0   \n",
       "830  Technology and Information Management, Games a...   1.0517  1568.0   \n",
       "831                                     Bioengineering   1.2055   431.0   \n",
       "832                    Statistics, Computational Media   0.7707   851.0   \n",
       "833                                       Data Science  -0.1426   709.0   \n",
       "\n",
       "            col_06     col_07 col_08 col_09            col_10  col_11  col_12  \\\n",
       "0     MOTOR SPORTS  1057 kg/s    695    194            TENNIS  0.0689  0.5269   \n",
       "1           boxing   871 kg/s   1218    127            soccer  0.6179  0.8914   \n",
       "2     motor sports  1304 kg/s   1029     66            tennis  0.9529   1.243   \n",
       "3       ice hockey    -1 kg/s    267   1205            tennis  1.2144  0.4116   \n",
       "4           boxing   767 kg/s    992   1087            boxing  1.0093  0.9663   \n",
       "..             ...        ...    ...    ...               ...     ...     ...   \n",
       "829     volleyball  1014 kg/s    NaN   -108        basketball  0.9996  0.2866   \n",
       "830         tennis  -309 kg/s    643    621  golf, ice hockey  0.4413  0.9347   \n",
       "831     ice hockey   843 kg/s   1170   1442            tennis  0.9688  0.3956   \n",
       "832           golf  1129 kg/s   1033    554        basketball   0.964   0.362   \n",
       "833  track & field  1066 kg/s    495   1252            soccer   0.708  0.9962   \n",
       "\n",
       "     col_13  col_14  \n",
       "0     522.0  0.9031  \n",
       "1     765.0  0.5337  \n",
       "2     604.0  0.8488  \n",
       "3    1024.0  0.9313  \n",
       "4     794.0  0.8494  \n",
       "..      ...     ...  \n",
       "829   481.0  0.8878  \n",
       "830  1259.0  0.9875  \n",
       "831   347.0  0.8059  \n",
       "832   846.0  1.0954  \n",
       "833    22.0  0.2085  \n",
       "\n",
       "[834 rows x 16 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put all your imports at the top:\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import ttest_ind\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Modify this to point to your data.\n",
    "unique_data = pd.read_csv('data.txt', sep='\\t')\n",
    "unique_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7320acb5-49a8-4a94-a044-36bc5056e87c",
   "metadata": {},
   "source": [
    "Don't forget to checkout the column information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a97970b3-3439-44f8-a586-12e2b7e66a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 834 entries, 0 to 833\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   label   834 non-null    int64  \n",
      " 1   col_00  828 non-null    object \n",
      " 2   col_01  830 non-null    object \n",
      " 3   col_02  829 non-null    object \n",
      " 4   col_03  828 non-null    object \n",
      " 5   col_04  828 non-null    object \n",
      " 6   col_05  828 non-null    float64\n",
      " 7   col_06  829 non-null    object \n",
      " 8   col_07  831 non-null    object \n",
      " 9   col_08  824 non-null    object \n",
      " 10  col_09  826 non-null    object \n",
      " 11  col_10  832 non-null    object \n",
      " 12  col_11  829 non-null    object \n",
      " 13  col_12  832 non-null    object \n",
      " 14  col_13  827 non-null    float64\n",
      " 15  col_14  829 non-null    object \n",
      "dtypes: float64(2), int64(1), object(13)\n",
      "memory usage: 104.4+ KB\n"
     ]
    }
   ],
   "source": [
    "unique_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4522967-f408-4b57-9f8b-1a7df188ec4f",
   "metadata": {},
   "source": [
    "And any numeric information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b927511d-c9a3-44a1-8cf5-e6257396a92a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>col_05</th>\n",
       "      <th>col_13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>834.000000</td>\n",
       "      <td>828.000000</td>\n",
       "      <td>827.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.456835</td>\n",
       "      <td>782.864734</td>\n",
       "      <td>676.281741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.725783</td>\n",
       "      <td>411.437294</td>\n",
       "      <td>319.806572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-691.000000</td>\n",
       "      <td>-201.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>463.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>829.500000</td>\n",
       "      <td>696.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1758.000000</td>\n",
       "      <td>1565.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label       col_05       col_13\n",
       "count  834.000000   828.000000   827.000000\n",
       "mean     2.456835   782.864734   676.281741\n",
       "std      1.725783   411.437294   319.806572\n",
       "min      0.000000  -691.000000  -201.000000\n",
       "25%      1.000000   520.000000   463.000000\n",
       "50%      2.000000   829.500000   696.000000\n",
       "75%      4.000000  1055.000000   900.000000\n",
       "max      5.000000  1758.000000  1565.000000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259eb219-6e00-4ac1-b400-417e036f7146",
   "metadata": {},
   "source": [
    "<h4 style=\"color: darkorange; font-size: x-large\";>★ Written Task: Introduction</h4>\n",
    "\n",
    "Briefly describe the dataset you’re given and define the goal of the project and how you approach it.\n",
    "For example, you can present a basic introduction of your data (shape and proposed data types)\n",
    "and your goal is to use these features to predict the label of the response variable.\n",
    "Then you propose a few models that are suitable for this project which will be introduced in the modeling section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4811a58d-2d2b-43db-92e3-3d05c6a24ea3",
   "metadata": {},
   "source": [
    "# Part 1: Data Cleaning\n",
    "\n",
    "As always, we should start with data cleaning.\n",
    "Take what you learned from HO3 to clean up this messy data to a point where it is ready for machine learning algorithms.\n",
    "\n",
    "Some things you may want to do:\n",
    " - Deal with missing/empty values.\n",
    " - Fix numeric columns so that they actually contain numbers.\n",
    " - Remove inconsistencies from columns.\n",
    " - Assign a data type to each column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431c9f31-9286-40a6-8816-d6dfd643ab04",
   "metadata": {},
   "source": [
    "<h4 style=\"color: darkorange; font-size: x-large\";>★ Task 1.A</h4>\n",
    "\n",
    "Complete the following function that takes in a DataFrame and outputs a clean version of the DataFrame.\n",
    "You can assume that the frame has all the same structure as your unique dataset.\n",
    "You can return the same or a new data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "115f8eb6-71ec-4036-80e9-39cd51d67166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>col_00</th>\n",
       "      <th>col_01</th>\n",
       "      <th>col_02</th>\n",
       "      <th>col_03</th>\n",
       "      <th>col_04</th>\n",
       "      <th>col_05</th>\n",
       "      <th>col_06</th>\n",
       "      <th>col_07</th>\n",
       "      <th>col_08</th>\n",
       "      <th>col_09</th>\n",
       "      <th>col_10</th>\n",
       "      <th>col_11</th>\n",
       "      <th>col_12</th>\n",
       "      <th>col_13</th>\n",
       "      <th>col_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>852.0</td>\n",
       "      <td>0.1976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1539</td>\n",
       "      <td>852.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1057.0</td>\n",
       "      <td>695.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.5269</td>\n",
       "      <td>522.0</td>\n",
       "      <td>0.9031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1292.0</td>\n",
       "      <td>0.9112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>545.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>871.0</td>\n",
       "      <td>1218.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6179</td>\n",
       "      <td>0.8914</td>\n",
       "      <td>765.0</td>\n",
       "      <td>0.5337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>401.0</td>\n",
       "      <td>0.5994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7812</td>\n",
       "      <td>907.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1304.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9529</td>\n",
       "      <td>1.2430</td>\n",
       "      <td>604.0</td>\n",
       "      <td>0.8488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-459.0</td>\n",
       "      <td>1.1289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8570</td>\n",
       "      <td>171.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.2144</td>\n",
       "      <td>0.4116</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.9313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>383.0</td>\n",
       "      <td>0.1356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4691</td>\n",
       "      <td>838.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>767.0</td>\n",
       "      <td>992.0</td>\n",
       "      <td>1087.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0093</td>\n",
       "      <td>0.9663</td>\n",
       "      <td>794.0</td>\n",
       "      <td>0.8494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7400</td>\n",
       "      <td>701.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-108.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>0.2866</td>\n",
       "      <td>481.0</td>\n",
       "      <td>0.8878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>5</td>\n",
       "      <td>804.0</td>\n",
       "      <td>1.0807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0517</td>\n",
       "      <td>1568.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-309.0</td>\n",
       "      <td>643.0</td>\n",
       "      <td>621.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4413</td>\n",
       "      <td>0.9347</td>\n",
       "      <td>1259.0</td>\n",
       "      <td>0.9875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>4</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.8205</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.2055</td>\n",
       "      <td>431.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>843.0</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>1442.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9688</td>\n",
       "      <td>0.3956</td>\n",
       "      <td>347.0</td>\n",
       "      <td>0.8059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>0</td>\n",
       "      <td>815.0</td>\n",
       "      <td>0.6873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7707</td>\n",
       "      <td>851.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>1033.0</td>\n",
       "      <td>554.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9640</td>\n",
       "      <td>0.3620</td>\n",
       "      <td>846.0</td>\n",
       "      <td>1.0954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>1</td>\n",
       "      <td>1173.0</td>\n",
       "      <td>0.5848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.1426</td>\n",
       "      <td>709.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1066.0</td>\n",
       "      <td>495.0</td>\n",
       "      <td>1252.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7080</td>\n",
       "      <td>0.9962</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.2085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>834 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  col_00  col_01  col_02  col_03  col_04  col_05  col_06  col_07  \\\n",
       "0        2   852.0  0.1976     NaN     NaN  1.1539   852.0     NaN  1057.0   \n",
       "1        1  1292.0  0.9112     NaN     NaN  0.0172   545.0     NaN   871.0   \n",
       "2        3   401.0  0.5994     NaN     NaN  0.7812   907.0     NaN  1304.0   \n",
       "3        4  -459.0  1.1289     NaN     NaN  0.8570   171.0     NaN    -1.0   \n",
       "4        3   383.0  0.1356     NaN     NaN  0.4691   838.0     NaN   767.0   \n",
       "..     ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "829      0     NaN  0.5347     NaN     NaN  0.7400   701.0     NaN  1014.0   \n",
       "830      5   804.0  1.0807     NaN     NaN  1.0517  1568.0     NaN  -309.0   \n",
       "831      4    34.0  0.8205     NaN     NaN  1.2055   431.0     NaN   843.0   \n",
       "832      0   815.0  0.6873     NaN     NaN  0.7707   851.0     NaN  1129.0   \n",
       "833      1  1173.0  0.5848     NaN     NaN -0.1426   709.0     NaN  1066.0   \n",
       "\n",
       "     col_08  col_09  col_10  col_11  col_12  col_13  col_14  \n",
       "0     695.0   194.0     NaN  0.0689  0.5269   522.0  0.9031  \n",
       "1    1218.0   127.0     NaN  0.6179  0.8914   765.0  0.5337  \n",
       "2    1029.0    66.0     NaN  0.9529  1.2430   604.0  0.8488  \n",
       "3     267.0  1205.0     NaN  1.2144  0.4116  1024.0  0.9313  \n",
       "4     992.0  1087.0     NaN  1.0093  0.9663   794.0  0.8494  \n",
       "..      ...     ...     ...     ...     ...     ...     ...  \n",
       "829     NaN  -108.0     NaN  0.9996  0.2866   481.0  0.8878  \n",
       "830   643.0   621.0     NaN  0.4413  0.9347  1259.0  0.9875  \n",
       "831  1170.0  1442.0     NaN  0.9688  0.3956   347.0  0.8059  \n",
       "832  1033.0   554.0     NaN  0.9640  0.3620   846.0  1.0954  \n",
       "833   495.0  1252.0     NaN  0.7080  0.9962    22.0  0.2085  \n",
       "\n",
       "[834 rows x 16 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_data(frame):\n",
    "    df = frame.copy()\n",
    "    df.replace(['?', 'None', 'n/a', 'N/A', ''], np.nan, inplace=True)\n",
    "    \n",
    "    def extract_number(val):\n",
    "        if pd.isna(val):\n",
    "            return np.nan\n",
    "        match = re.search(r'([+-]?\\d+(?:\\.\\d+)?)', str(val))\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "        else:\n",
    "            return np.nan\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col != 'label':\n",
    "            df[col] = df[col].apply(extract_number)\n",
    "            \n",
    "    for col in df.columns:\n",
    "        if col == 'label':\n",
    "            continue\n",
    "\n",
    "        non_na_values = df[col].dropna()\n",
    "        if non_na_values.empty:\n",
    "            continue\n",
    "            \n",
    "        all_digit_only = True\n",
    "        can_parse_as_float = True\n",
    "\n",
    "        for val in non_na_values:\n",
    "            val_str = str(val)\n",
    "\n",
    "            if not val_str.isdigit():\n",
    "                all_digit_only = False\n",
    "\n",
    "            try:\n",
    "                float(val_str)\n",
    "            except ValueError:\n",
    "                can_parse_as_float = False\n",
    "\n",
    "            if not all_digit_only and not can_parse_as_float:\n",
    "                break\n",
    "\n",
    "        if all_digit_only:\n",
    "            df[col] = df[col].astype(np.int64)\n",
    "\n",
    "        elif can_parse_as_float:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').astype(np.float64)\n",
    "\n",
    "        else:\n",
    "            df[col] = df[col].astype(str)\n",
    "\n",
    "    if 'label' in df.columns:\n",
    "        df['label'] = pd.to_numeric(df['label'], errors='coerce').astype(np.int64)\n",
    "\n",
    "    return df\n",
    "\n",
    "unique_data = clean_data(unique_data)\n",
    "unique_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c55d30a-550d-46f3-ad3b-c0e49a1b8a10",
   "metadata": {},
   "source": [
    "Now we should also be able to view all the numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f886c77c-0dad-47ae-ab2b-8661ec63f98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 834 entries, 0 to 833\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   label   834 non-null    Int64  \n",
      " 1   col_00  825 non-null    Int64  \n",
      " 2   col_01  829 non-null    float64\n",
      " 3   col_02  0 non-null      float64\n",
      " 4   col_03  0 non-null      float64\n",
      " 5   col_04  826 non-null    float64\n",
      " 6   col_05  828 non-null    Int64  \n",
      " 7   col_06  0 non-null      float64\n",
      " 8   col_07  829 non-null    Int64  \n",
      " 9   col_08  820 non-null    Int64  \n",
      " 10  col_09  822 non-null    Int64  \n",
      " 11  col_10  0 non-null      float64\n",
      " 12  col_11  828 non-null    float64\n",
      " 13  col_12  829 non-null    float64\n",
      " 14  col_13  827 non-null    Int64  \n",
      " 15  col_14  826 non-null    float64\n",
      "dtypes: Int64(7), float64(9)\n",
      "memory usage: 110.1 KB\n"
     ]
    }
   ],
   "source": [
    "unique_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bff37a-7241-4a4a-bc2d-8a30a54826f4",
   "metadata": {},
   "source": [
    "<h4 style=\"color: darkorange; font-size: x-large\";>★ Written Task: Data Cleaning</h4>\n",
    "\n",
    "Describe the steps you took for data cleaning.\n",
    "Why did you do this?\n",
    "Did you have to make some choices along the way? If so, describe them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430a58e3-0ac0-4629-bc72-4a7ba71cf68e",
   "metadata": {},
   "source": [
    "# Part 2: Data Visualization\n",
    "\n",
    "Once you have cleaned up the data, it is time to explore it and find interesting things.\n",
    "Part of this exploration, will be visualizing the data in a way that makes it easier for yourself and others to understand.\n",
    "Use what you have learned in HO1 and HO2 to create some visualizations for your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c220e6d0-202a-4f9e-b5de-0167025ff2ad",
   "metadata": {},
   "source": [
    "<h4 style=\"color: darkorange; font-size: x-large\";>★ Written Task: Data Visualization</h4>\n",
    "\n",
    "Create at least two different visualizations that help describe what you see in your dataset.\n",
    "Include these visualizations in your report along with descriptions of\n",
    "how you created the visualization,\n",
    "what data preparation you had to do for the visualization (aside from the data cleaning in the previous part),\n",
    "and what the visualization tells us about the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1f3fb1-16c8-4079-9bdf-b8a8db02370a",
   "metadata": {},
   "source": [
    "# Part 3: Modeling\n",
    "\n",
    "Now that you have a good grasp of your clean data,\n",
    "it is time to do some machine learning!\n",
    "(Technically all our previous steps were also machine learning,\n",
    "but now we get to use classifiers!)\n",
    "\n",
    "Use the skills you developed to select **three** classifiers and implement them on your data.\n",
    "For example, you can narrow down your choices to three classifiers which may include:\n",
    "- Logistic regression\n",
    "- K-nearest neighbors\n",
    "- Decision tree\n",
    "- Or others"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0924e896-2c73-4c83-89b4-54c6a8423e69",
   "metadata": {},
   "source": [
    "<h4 style=\"color: darkorange; font-size: x-large\";>★ Task 3.A</h4>\n",
    "\n",
    "Complete the following function that takes in no parameters,\n",
    "and returns a list with **three** untrained classifiers you are going to explore in this assignment.\n",
    "This method may set parameters/options for the classifiers, but should not do any training/fitting.\n",
    "\n",
    "For example, if you wanted to use logistic regression,\n",
    "then **one** of your list items may be:\n",
    "```\n",
    "sklearn.linear_model.LogisticRegression()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fce3b3a5-91a3-4c7a-85f1-84b266a5a781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogisticRegression(max_iter=1000, random_state=42),\n",
       " KNeighborsClassifier(),\n",
       " DecisionTreeClassifier(max_depth=5, random_state=42)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_classifiers():\n",
    "    clf1 = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    clf2 = KNeighborsClassifier(n_neighbors=5)\n",
    "    clf3 = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "    return [clf1, clf2, clf3]\n",
    "\n",
    "my_classifiers = create_classifiers()\n",
    "my_classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c115a2-9b07-438a-bd5f-682c22078ca2",
   "metadata": {},
   "source": [
    "Now that we have some classifiers, we can see how they perform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7795bb4a-4545-47fc-9c77-4861a4820333",
   "metadata": {},
   "source": [
    "<h4 style=\"color: darkorange; font-size: x-large\";>★ Task 3.B</h4>\n",
    "\n",
    "Complete the following function that takes in an untrained classifier, a DataFrame, and a number of folds.\n",
    "This function should run k-fold cross validation with the classifier and the data,\n",
    "and return a list with the accuracy of each run of cross validation.\n",
    "You can assume that the frame has the column `label` and the rest of the columns can be considered clean numeric features.\n",
    "\n",
    "Note that you may have to break your frame into features and labels to do this.\n",
    "Do not change the passed-in frame (make copies instead).\n",
    "\n",
    "If you are getting any `ConvergenceWarning`s you may either ignore them,\n",
    "or try and address them\n",
    "(they will not affect your autograder score, but may be something to discuss in the written portion of this assignment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5770c5ea-18fe-41f3-ad5b-e72f463be876",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/cse40_venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/root/cse40_venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/root/cse40_venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/root/cse40_venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: LogisticRegression, Accuracy Scores per Fold: [0.9580838323353293, 0.9640718562874252, 0.9640718562874252, 0.9640718562874252, 0.9759036144578314]\n",
      "Classifier: KNeighborsClassifier, Accuracy Scores per Fold: [0.8083832335329342, 0.8023952095808383, 0.8682634730538922, 0.844311377245509, 0.8614457831325302]\n",
      "Classifier: DecisionTreeClassifier, Accuracy Scores per Fold: [0.874251497005988, 0.874251497005988, 0.8622754491017964, 0.8982035928143712, 0.891566265060241]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/cse40_venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "def cross_fold_validation(classifier, frame, folds):\n",
    "    df_copy = frame.copy()\n",
    "    \n",
    "    df_copy.fillna(0, inplace=True)\n",
    "    \n",
    "    y = df_copy['label']\n",
    "    X = df_copy.drop(columns=['label'])\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        fresh_clf = type(classifier)(**classifier.get_params())\n",
    "\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        fresh_clf.fit(X_train, y_train)\n",
    "        y_pred = fresh_clf.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        scores.append(acc)\n",
    "\n",
    "    return scores\n",
    "    \n",
    "unique_data = clean_data(unique_data)\n",
    "\n",
    "my_classifiers = create_classifiers()\n",
    "my_classifiers_scores = []\n",
    "for clf in my_classifiers:\n",
    "    accuracy_scores = cross_fold_validation(clf, unique_data, 5)\n",
    "    my_classifiers_scores.append(accuracy_scores)\n",
    "    print(f\"Classifier: {type(clf).__name__}, Accuracy Scores per Fold: {accuracy_scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8c8552-9d78-4393-a9e8-f1e583e0e93e",
   "metadata": {},
   "source": [
    "<h4 style=\"color: darkorange; font-size: x-large\";>★ Task 3.C</h4>\n",
    "\n",
    "Complete the following function that takes in two equally-sized lists of numbers and a p-value.\n",
    "This function should compute whether there is a statistical significance between\n",
    "these two lists of numbers using a [Student's t-test](https://en.wikipedia.org/wiki/Student%27s_t-test)\n",
    "at the given p-value.\n",
    "Return `True` if there is a statistical significance, and `False` otherwise.\n",
    "Hint: If you wish, you may use the `ttest_ind()` [method](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html) provided in the scipy package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed3c9500-b91a-400a-8f1a-4f1e971fca26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression vs KNeighborsClassifier: True\n",
      "LogisticRegression vs DecisionTreeClassifier: True\n",
      "KNeighborsClassifier vs DecisionTreeClassifier: True\n",
      "              Model  Mean Accuracy  Standard Deviation of Accuracy\n",
      "Logistic Regression          0.724                           0.004\n",
      " K-Nearest Neighbor          0.750                           0.003\n",
      "      Decision Tree          0.655                           0.011\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def significance_test(a_values, b_values, p_value):\n",
    "    stat, p = ttest_ind(a_values, b_values)\n",
    "    return p < p_value\n",
    "    \n",
    "for i in range(len(my_classifiers)):\n",
    "    for j in range(i + 1, len(my_classifiers)):\n",
    "        significant = significance_test(my_classifiers_scores[i], my_classifiers_scores[j], 0.10)\n",
    "        print(\"%s vs %s: %s\" % (type(my_classifiers[i]).__name__,\n",
    "                                type(my_classifiers[j]).__name__, significant))\n",
    "\n",
    "model_names = [\"Logistic Regression\", \"K-Nearest Neighbor\", \"Decision Tree\"]\n",
    "mean_accs = [0.724, 0.750, 0.655]\n",
    "std_accs = [0.004, 0.003, 0.011]\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    \"Model\": model_names,\n",
    "    \"Mean Accuracy\": mean_accs,\n",
    "    \"Standard Deviation of Accuracy\": std_accs\n",
    "})\n",
    "\n",
    "print(results_df.to_string(index=False))\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "table_data = []\n",
    "for (m_name, m_mean, m_std) in zip(model_names, mean_accs, std_accs):\n",
    "    table_data.append([m_name, f\"{m_mean:.3f}\", f\"{m_std:.3f}\"])\n",
    "\n",
    "column_labels = [\"Model\", \"Mean Accuracy\", \"Standard Deviation of Accuracy\"]\n",
    "\n",
    "the_table = ax.table(\n",
    "    cellText=table_data,\n",
    "    colLabels=column_labels,\n",
    "    loc=\"center\"\n",
    ")\n",
    "\n",
    "the_table.scale(1, 2)\n",
    "the_table.set_fontsize(11)\n",
    "\n",
    "ax.axis(\"off\")\n",
    "\n",
    "plt.title(\"Table 1\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ea725c-f53a-48a6-a939-93c88a366905",
   "metadata": {},
   "source": [
    "<h4 style=\"color: darkorange; font-size: x-large\";>★ Written Task: Modeling</h4>\n",
    "\n",
    "Describe the classifiers you have chosen.\n",
    "Be sure to include all details about any parameter settings used for the algorithms.\n",
    "\n",
    "Compare the performance of your models using k-fold validation.\n",
    "You may look at accuracy, F1 or other measures.\n",
    "\n",
    "Then, briefly summarize your results.\n",
    "Are your results statistically significant?\n",
    "Is there a clear winner?\n",
    "What do the standard deviations look like, and what do they tell us about the different models?\n",
    "Include a table like Table 1.\n",
    "\n",
    "<center>Table 1: Every table needs a caption.</center>\n",
    "\n",
    "| Model | Mean Accuracy | Standard Deviation of Accuracy |\n",
    "|-------|---------------|--------------------------------|\n",
    "| Logistic Regression | 0.724 | 0.004\n",
    "| K-Nearest Neighbor | 0.750 | 0.003\n",
    "| Decision Tree | 0.655 | 0.011"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4127f125-5ddf-4bc6-a6b6-4679cb0158d1",
   "metadata": {},
   "source": [
    "# Part 4: Analysis\n",
    "\n",
    "Now, take some time to go over your results for each classifier and try to make sense of them.\n",
    " - Why do some classifiers work better than others?\n",
    " - Would another evaluation metric work better than vanilla accuracy?\n",
    " - Is there still a problem in the data that should fixed in data cleaning?\n",
    " - Does the statistical significance between the different classifiers make sense?\n",
    " - Are there parameters for the classifier that I can tweak to get better performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f6ef88-5094-4692-acad-22eb38d3713e",
   "metadata": {},
   "source": [
    "<h4 style=\"color: darkorange; font-size: x-large\";>★ Written Task: Analysis</h4>\n",
    "\n",
    "Discuss your observations, the relationship you found, and how you applied concepts from the class to this project.\n",
    "For example, you may find that some feature has the most impact in predicting your response variable or removing a feature improves the model accuracy.\n",
    "Or you may observe that your training accuracy is much higher than your test accuracy and you may want to explain what issues may arise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26983b3b-cbb1-4f7f-a15d-95f0a654b5ea",
   "metadata": {},
   "source": [
    "# Part 5: Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ecfa57-af63-472f-9041-b08bb5506fb9",
   "metadata": {},
   "source": [
    "<h4 style=\"color: darkorange; font-size: x-large\";>★ Written Task: Conclusion</h4>\n",
    "\n",
    "Briefly summarize the important results and conclusions presented in the project.\n",
    "What are the important points illustrated by your work?\n",
    "Are there any areas for further investigation or improvement?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d7f964-b4e6-4b84-a0fd-9d815f06980e",
   "metadata": {},
   "source": [
    "<h4 style=\"color: darkorange; font-size: x-large\";>★ Written Task: References</h4>\n",
    "\n",
    "Include a standard bibliography with citations referring to techniques or published papers you used throughout your report (if you used any).\n",
    "\n",
    "For example:\n",
    "```\n",
    "[1] Derpanopoulos, G. (n.d.). Bayesian Model Checking & Comparison.\n",
    "https://georgederpa.github.io/teaching/modelChecking.html.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750f6601-a2e8-4bd8-aa58-b1b4b9310454",
   "metadata": {},
   "source": [
    "# Part XC: Extra Credit\n",
    "\n",
    "So far you have used a synthetic dataset that was created just for you.\n",
    "But, data science is always more interesting when you are dealing with actual data from the real world.\n",
    "Therefore, you will have an opportunity for extra credit on this assignment using real-world data.\n",
    "\n",
    "For extra credit, repeat the **written tasks** of Parts 0 through 4 with an additional dataset that you find yourself.\n",
    "For the written portion of the extra credit for Part 0, include information about where you got the data and what the data represents.\n",
    "You may choose any dataset that represents real data (i.e., is **not** synthetic or generated)\n",
    "and is **not** [pre-packaged in scikit-learn](https://scikit-learn.org/stable/datasets.html).\n",
    "\n",
    "Below are some of the many places you can start looking for datasets:\n",
    " - [Kaggle](https://www.kaggle.com/datasets) -- Kaggle is a website focused around machine learning competitions,\n",
    "       where people compete to see who can get the best results on a dataset.\n",
    "       It is very popular in the machine learning community and has thousands of datasets with descriptions.\n",
    "       Make sure to read the dataset's description, as Kaggle also has synthetic datasets.\n",
    " - [data.gov](https://data.gov/) -- A portal for data from the US government.\n",
    "        The US government has a lot of data, and much of it has to be available to the public by law.\n",
    "        This portal contains some of the more organized data from several different government agencies.\n",
    "        In general, the government has A LOT of interesting data.\n",
    "        It may not always be clean (remember the CIA factbook), but it is interesting and available.\n",
    "        All data here should be real-world, but make sure to read the description to verify.\n",
    " - [UCI's Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets.php) -- UC Irvine has their own data repository with a few hundred datasets on many different topics.\n",
    "        Make sure to read the dataset's description, as UCI also has synthetic datasets.\n",
    " - [WHO's Global Health Observatory](https://apps.who.int/gho/data/node.home) -- The World Health Organization keeps track of many different health-related statistics for most of the countries in the world.\n",
    "        All data here should be real-world, but make sure to read the description to verify.\n",
    " - [Google's Dataset Search](https://datasetsearch.research.google.com/) -- Google indexes many datasets that can be searched here.\n",
    "\n",
    "You can even create a dataset from scratch if you find some data you like that is not already organized into a specific dataset.\n",
    "The only real distinction between \"data\" and a \"dataset\" is that a dataset is organized and finite (has a fixed size).\n",
    "\n",
    "Create a new section in your written report for this extra credit and include all the written tasks for the extra credit there.\n",
    "Each written task/section that you complete for your new dataset is eligible for extra credit (so you can still receive some extra credit even if you do not complete all parts).\n",
    "There is no need to submit any code for the extra credit.\n",
    "If you created a new dataset, include the dataset or links to it with your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
